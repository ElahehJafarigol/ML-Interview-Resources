{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 🔥 **Master Pandas in Record Time (80/20 Rule Approach)**  \n",
        "\n",
        "To **master Pandas fast**, we’ll **skip traditional tutorials** and focus on the **20% of functions** that deliver **80% of real-world results**. Instead of passive reading, we’ll use **high-intensity active learning** with **speed challenges, cheat sheets, and forced recall**."
      ],
      "metadata": {
        "id": "tr9O9puAWf0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔹 Step 1: The 12 Essential Pandas Functions (15 min)**\n",
        "Forget **comprehensive documentation**—you only need these **12 functions** to do 80% of data manipulation tasks:\n",
        "\n",
        "| **Category** | **Function** | **What It Does** | **Example** |\n",
        "|-------------|-------------|------------------|-------------|\n",
        "| **Loading Data** | `pd.read_csv()` | Reads CSV files | `df = pd.read_csv(\"data.csv\")` |\n",
        "| **Basic Inspection** | `df.head()` | Shows first 5 rows | `df.head(10)` |\n",
        "| | `df.info()` | Data types & missing values | `df.info()` |\n",
        "| **Selecting Data** | `df[['col1', 'col2']]` | Selects specific columns | `df[['Age', 'Fare']]` |\n",
        "| | `df.loc[]` | Selects rows/columns by labels | `df.loc[2, 'Age']` |\n",
        "| | `df.iloc[]` | Selects rows/columns by index | `df.iloc[0:5, :]` |\n",
        "| **Filtering Data** | `df[df['Age'] > 30]` | Filters rows | `df[df['Survived'] == 1]` |\n",
        "| **Sorting Data** | `df.sort_values()` | Sorts DataFrame | `df.sort_values(by='Age', ascending=False)` |\n",
        "| **Missing Data** | `df.dropna()` | Removes missing values | `df.dropna(subset=['Age'])` |\n",
        "| | `df.fillna()` | Fills missing values | `df.fillna(df['Age'].mean())` |\n",
        "| **Group & Aggregate** | `df.groupby().agg()` | Groups & calculates stats | `df.groupby('Pclass')['Fare'].mean()` |\n",
        "| **Apply Functions** | `df.apply()` | Runs a function on a column | `df['Age'] = df['Age'].apply(lambda x: x + 1)` |\n",
        "\n",
        "🎯 **Your Task (15 min)**  \n",
        "- **Write down these 12 functions** (no copy-pasting).  \n",
        "- **Summarize each in 1 sentence** (forces clarity).  \n",
        "- **Look at them, then try to recall them from memory**.  "
      ],
      "metadata": {
        "id": "JYhQ2R8_xTg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔹 Step 2: Ultra-Fast Data Challenge (30 min)**\n",
        "💡 **Why?** Active learning forces **instant application** → **higher retention**.\n",
        "\n",
        "### **🔥 Challenge: Titanic Dataset Speed Run**\n",
        "💾 Load the dataset:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "```\n",
        "\n",
        "### **⏳ Timer Set: 30 min**\n",
        "Solve **these 5 tasks as fast as possible** using only **Google + docs** (no tutorials).  \n",
        "- **(5 min)** Find the number of missing values in each column.  \n",
        "- **(5 min)** Select only passengers from class **Pclass = 1**.  \n",
        "- **(5 min)** Calculate the **average age** of survivors.  \n",
        "- **(5 min)** Sort passengers by **Fare** (highest to lowest).  \n",
        "- **(10 min)** Fill missing **Age** values with the median of each `Pclass`.  \n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Try solving all 5 challenges **without looking at docs first**.  \n",
        "- If stuck, **Google only what you need**, then redo it **from memory**.  \n",
        "\n",
        "🚀 **Bonus: Do it again tomorrow & cut time in half.**  "
      ],
      "metadata": {
        "id": "3EuLU9M33WUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas practice\n",
        "\n",
        "# Load the dataset\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Number of missinf values in each column\n",
        "#print(\"Number of missing values in each column\")\n",
        "#print(df.info())\n",
        "\n",
        "df_1 = df[df[\"Pclass\"] == 1]\n",
        "#print(\"Passengers from class 1\")\n",
        "#print(df_1.head())\n",
        "\n",
        "# average age of survivors\n",
        "df_survived = df[df[\"Survived\"] == 1]\n",
        "avg_age = df[\"Age\"].mean()\n",
        "print(f\"Average age of survivors: {avg_age}\")\n",
        "\n",
        "# Sort passengers by fare (ascending = False)\n",
        "df_sorted = df.sort_values(by=\"Fare\", ascending=False)\n",
        "#print(\"Sorted list\")\n",
        "#print(df_sorted.head())\n",
        "\n",
        "# Missing values\n",
        "\n",
        "df[\"Age\"] = df[\"Age\"].fillna(df.groupby(\"Pclass\")[\"Age\"].transform(lambda x: x.median()))\n",
        "#print(df.info())"
      ],
      "metadata": {
        "id": "-Sk3gqS_3jSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a149263c-032b-449d-f09e-aa0e0165c852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average age of survivors: 29.69911764705882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔹 Step 3: Teach Pandas in 5 Minutes (15 min)**\n",
        "💡 **Why?** The **Feynman Technique** says if you can’t explain it **simply**, you don’t understand it.\n",
        "\n",
        "🎤 **Your Task:**  \n",
        "- Explain **Pandas basics** to me **in plain English** (or write a 5-line summary).  \n",
        "- If you struggle, **go back to Step 1 & refine your cheat sheet**.  \n",
        "- If you do well, **I’ll challenge you with advanced scenarios**.  "
      ],
      "metadata": {
        "id": "QvUVbSDSWSOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***My summary:***  *Pandas is used for data manipulation of data stored in the format of dataframes. read files df.read_cv(url/local path) We can explore the df by df.head() and df.info(). I can group the data by categorical variable levels using df.group_by(by=\"variable\", ascending = True) and then aggregate them using mean() od median(). Apply function and transorm is a bit challenging for me, but you can use them to apply lambda function to each group or a subset. To slice the data we can use `df.iloc[0:row, 0:col]`. I can create a df of a subset of the original df by putting it into braclkets (`df[df[\"Fare\"] > 50])`*."
      ],
      "metadata": {
        "id": "UVZtVByiRVx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔹 Step 4: Real-World Integration (30 min)**\n",
        "💡 **Why?** The best way to retain Pandas is to use it in a **real-world** scenario.\n",
        "\n",
        "### **🔥 Mini-Project: Titanic Data Report**\n",
        "🔹 Using Pandas, **create a report answering these:**  \n",
        "1. How many passengers survived vs. died?  \n",
        "2. What was the **average ticket price per class**?  \n",
        "3. Who was the **oldest survivor**?  \n",
        "4. What percentage of survivors were **female vs. male**?  \n",
        "5. **Export your results** to a CSV file.  "
      ],
      "metadata": {
        "id": "3RvxjAFDV-t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Real world integration\n",
        "# Passengers dies vs survived\n",
        "s = df[df[\"Survived\"] == 1]\n",
        "s_count = len(s)\n",
        "d = df[df[\"Survived\"] == 0]\n",
        "ratio = float(len(s) / len(d))\n",
        "print(f\"The number of passengers who died is {len(s)} and the number of passengers who survived is {len(d)} and the ratio is {ratio}\")\n",
        "\n",
        "# Average ticket price per class\n",
        "average_fare_per_class = df.groupby(\"Pclass\")[\"Fare\"].mean()\n",
        "\n",
        "# The oldest survivor\n",
        "d.sort_values(by=\"Age\", ascending=False)\n",
        "print(\"The oldest passenger who survived is\", d[\"Name\"][0], \", age:\", int(df[\"Age\"][0]))\n",
        "oldest_survivor_age = int(df[\"Age\"][0])\n",
        "\n",
        "# Percentage of male vs female\n",
        "m = s[s[\"Sex\"] == \"male\"]\n",
        "f = s[s[\"Sex\"] == \"female\"]\n",
        "male_rate = (len(m) / (len(m) + len(f))) * 100\n",
        "female_rate = (len(f) / (len(m) + len(f))) * 100\n",
        "print(f\"The percentage of male passengers is {male_rate}\")\n",
        "print(f\"The percentage of female passengers is {female_rate}\")\n",
        "# Creating a dictionary for better readability\n",
        "gender_proportion = {\n",
        "    \"female\": female_rate,\n",
        "    \"male\": male_rate\n",
        "}\n",
        "\n",
        "# Creating dictionary for survival rate by gender\n",
        "gender_proportion = {\"female\": female_rate, \"male\": male_rate}\n",
        "gender_proportion_df = pd.DataFrame([gender_proportion])  # Convert to DataFrame\n",
        "\n",
        "survival_rate_df = pd.DataFrame([gender_proportion], index = [\"gender_proportion\"])\n",
        "# Export to csv\n",
        "summary_df = pd.DataFrame({\n",
        "    \"Survivors\" : [s_count],\n",
        "    \"Agerage fare per class\": [average_fare_per_class.tolist()],\n",
        "    \"Oldest survivor age\": [oldest_survivor_age],\n",
        "    \"Survival rate by Gender\": [gender_proportion]\n",
        "})\n",
        "\n",
        "summary_df\n",
        "summary_df.to_csv(\"summary.csv\", index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuzNWF9LSm_Z",
        "outputId": "c5d887b7-1f5f-4c23-f182-8942916bc834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of passengers who died is 342 and the number of passengers who survived is 549 and the ratio is 0.6229508196721312\n",
            "The oldest passenger who survived is Braund, Mr. Owen Harris , age: 22\n",
            "The percentage of male passengers is 31.871345029239766\n",
            "The percentage of female passengers is 68.12865497076024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "💻 **Code Outline:**\n",
        "```python\n",
        "# Number of survivors\n",
        "survivors_count = df['Survived'].value_counts()\n",
        "\n",
        "# Average Fare per class\n",
        "fare_per_class = df.groupby('Pclass')['Fare'].mean()\n",
        "\n",
        "# Oldest survivor\n",
        "oldest_survivor = df[df['Survived'] == 1]['Age'].max()\n",
        "\n",
        "# Gender breakdown of survivors\n",
        "survival_rate_gender = df[df['Survived'] == 1]['Sex'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Export to CSV\n",
        "summary_df = pd.DataFrame({\n",
        "    'Survivors': survivors_count,\n",
        "    'Avg Fare per Class': fare_per_class,\n",
        "    'Oldest Survivor Age': oldest_survivor,\n",
        "    'Survival Rate by Gender': survival_rate_gender\n",
        "})\n",
        "\n",
        "summary_df.to_csv(\"titanic_summary.csv\", index=False)\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Run this code and **modify it to add your own insights**.  \n",
        "- Once done, **summarize your findings in 3 bullet points**.  \n",
        "\n",
        "🚀 **Bonus: Present your findings in 2 minutes as if explaining to a manager.**  \n",
        "\n",
        "---\n",
        "\n",
        "### **🔹 Final Step: Speed Reinforcement (15 min)**\n",
        "💡 **Why?** **Speed drills force pattern recognition** → **expert-level fluency**.\n",
        "\n",
        "⏳ **Timer Set: 15 min**\n",
        "- **Look away from your screen.**\n",
        "- Write down from memory:  \n",
        "  - The **12 essential Pandas functions**.  \n",
        "  - How to **load, filter, group, and export data**.  \n",
        "- **Compare to the cheat sheet.**  \n",
        "- **Repeat daily for 3 days.** 🚀"
      ],
      "metadata": {
        "id": "zaFEo1hxWMrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's **push your Pandas skills further** with **advanced challenges** 🚀  \n",
        "\n",
        "---\n",
        "\n",
        "## **🔥 Challenge 1: Complex Grouping & Aggregation**\n",
        "🔹 **Task**:  \n",
        "Using the Titanic dataset, **group by** both **Pclass** and **Sex**, then compute:  \n",
        "- The **average fare** paid per group  \n",
        "- The **median age** per group  \n",
        "- The **survival rate per group**  \n",
        "\n",
        "🔹 **Hint:**  \n",
        "- You'll need `groupby()` with **multiple columns**.\n",
        "- Use `.agg()` to apply multiple functions at once.\n",
        "- Compute **survival rate** as `mean()` on the `Survived` column.\n",
        "\n",
        "🎯 **Goal:** Understand **multi-level grouping** and using `.agg()` effectively.  "
      ],
      "metadata": {
        "id": "DdhdpTk3VLVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby([\"Pclass\", \"Sex\"]).agg(\n",
        "    {\n",
        "        \"Fare\": \"mean\",\n",
        "        \"Age\": \"median\",\n",
        "        \"Survived\": \"mean\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "SEFq7k7LVW7l",
        "outputId": "06890185-bbc5-432f-81c5-c7b5b22e46c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Fare   Age  Survived\n",
              "Pclass Sex                               \n",
              "1      female  106.125798  35.5  0.968085\n",
              "       male     67.226127  37.0  0.368852\n",
              "2      female   21.970121  28.5  0.921053\n",
              "       male     19.741782  29.0  0.157407\n",
              "3      female   16.118810  24.0  0.500000\n",
              "       male     12.661633  24.0  0.135447"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3b6a984-489f-464d-94d1-a94c8f1f2f54\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Fare</th>\n",
              "      <th>Age</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>female</th>\n",
              "      <td>106.125798</td>\n",
              "      <td>35.5</td>\n",
              "      <td>0.968085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>male</th>\n",
              "      <td>67.226127</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.368852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
              "      <th>female</th>\n",
              "      <td>21.970121</td>\n",
              "      <td>28.5</td>\n",
              "      <td>0.921053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>male</th>\n",
              "      <td>19.741782</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.157407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
              "      <th>female</th>\n",
              "      <td>16.118810</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>male</th>\n",
              "      <td>12.661633</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.135447</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3b6a984-489f-464d-94d1-a94c8f1f2f54')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3b6a984-489f-464d-94d1-a94c8f1f2f54 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3b6a984-489f-464d-94d1-a94c8f1f2f54');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8ec7fa66-527a-4adc-84f9-a5bc9cd6e63f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ec7fa66-527a-4adc-84f9-a5bc9cd6e63f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8ec7fa66-527a-4adc-84f9-a5bc9cd6e63f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \")\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.853902221157796,\n        \"min\": 12.661632564841499,\n        \"max\": 106.12579787234043,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          106.12579787234043,\n          67.22612704918032,\n          12.661632564841499\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.546770832355223,\n        \"min\": 24.0,\n        \"max\": 37.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          37.0,\n          24.0,\n          28.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3642599646526349,\n        \"min\": 0.13544668587896252,\n        \"max\": 0.9680851063829787,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9680851063829787,\n          0.36885245901639346,\n          0.13544668587896252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **🔥 Challenge 2: Apply Custom Functions**\n",
        "🔹 **Task**:  \n",
        "Write a function that:\n",
        "- **Categorizes passengers' ages** into **\"Child\" (≤16), \"Adult\" (>16 & ≤60), \"Senior\" (>60)**.\n",
        "- Use **`.apply()`** to create a new column `\"AgeGroup\"`.\n",
        "\n",
        "🔹 **Hint:**  \n",
        "- Define a **custom function** with `lambda`.\n",
        "- Apply it to the `\"Age\"` column.\n",
        "\n",
        "🎯 **Goal:** Understand **`.apply()` for row-wise transformations**."
      ],
      "metadata": {
        "id": "en2q6gFQW_3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"AgeGroup\"] = df[\"Age\"].apply(lambda x : \"Child\" if x <= 16 else (\"Senior\" if x > 60 else \"Adult\"))\n",
        "#df[\"AgeGroup\"].head()"
      ],
      "metadata": {
        "id": "_zVXig3QVW3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **🔥 Challenge 3: Advanced Filtering**\n",
        "🔹 **Task**:  \n",
        "Filter the dataset to show:\n",
        "- Passengers who **paid more than 3× the median Fare**.\n",
        "- Were **not in 3rd class**.\n",
        "- Were **either Female OR under 18**.\n",
        "\n",
        "🎯 **Goal:** Learn **complex filtering conditions**."
      ],
      "metadata": {
        "id": "rZQoRWjdaiCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df[\n",
        "    (df[\"Fare\"] > df[\"Fare\"].median() * 3) &\n",
        "    (df[\"Pclass\"] != 3) &\n",
        "    ((df[\"Sex\"] == \"female\") | (df[\"Age\"] < 18))\n",
        "]"
      ],
      "metadata": {
        "id": "yhkdvhnJVOZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **🔥 Challenge 4: Pivot Tables**\n",
        "🔹 **Task**:  \n",
        "Create a **pivot table** showing:\n",
        "- The **average fare paid** for each combination of `\"Pclass\"` and `\"Sex\"`.  \n",
        "- Fill missing values with **0**.  \n",
        "- Add `margins=True` to include totals.\n",
        "\n",
        "🎯 **Goal:** Understand **pivot tables for data summarization**."
      ],
      "metadata": {
        "id": "4E5Pb_jI-imN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **📊 Pivot Table in Pandas**\n",
        "A **pivot table** in Pandas is a way to **summarize, aggregate, and analyze data** by reorganizing it. It is similar to pivot tables in Excel.\n",
        "\n",
        "#### **🔍 Understanding Pivot Table Structure in Pandas**\n",
        "When creating a pivot table, it's essential to know:\n",
        "1. **What goes in the `values`?** → The numerical data you want to summarize.\n",
        "2. **What goes in the `index`?** → The categories that define the rows.\n",
        "3. **What goes in the `columns`?** → The categories that define the columns.\n",
        "4. **What function is used (`aggfunc`)?** → How the data is summarized (sum, mean, count, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "##### **🔹 How to Decide What Goes Where?**\n",
        "| **Question** | **Pivot Parameter** | **Example** |\n",
        "|-------------|----------------|-----------|\n",
        "| **What numeric data do I want to summarize?** | `values` | `\"fare\"` (numeric column) |\n",
        "| **What should be in rows?** | `index` | `\"pclass\"` (categorical) |\n",
        "| **What should be in columns?** | `columns` | `\"sex\"` (categorical) |\n",
        "| **How should the data be summarized?** | `aggfunc` | `\"mean\"` (average) |\n",
        "\n",
        "---\n",
        "\n",
        "##### **🔍 How to Choose the Right Pivot Table?**\n",
        "1. **If you want to see total fare per class & gender:**\n",
        "   ```python\n",
        "   titanic.pivot_table(values=\"fare\", index=\"pclass\", columns=\"sex\", aggfunc=\"sum\")\n",
        "   ```\n",
        "   - 📌 **Rows = `pclass` (1st, 2nd, 3rd)**\n",
        "   - 📌 **Columns = `sex` (male, female)**\n",
        "   - 📌 **Values = Total Fare**\n",
        "\n",
        "2. **If you want to count how many passengers exist in each category:**\n",
        "   ```python\n",
        "   titanic.pivot_table(values=\"fare\", index=\"pclass\", columns=\"sex\", aggfunc=\"count\")\n",
        "   ```\n",
        "   - 📌 Counts number of passengers instead of averaging.\n",
        "\n",
        "3. **If you want to see survival rates per class & gender:**\n",
        "   ```python\n",
        "   titanic.pivot_table(values=\"survived\", index=\"pclass\", columns=\"sex\", aggfunc=\"mean\")\n",
        "   ```\n",
        "   - 📌 **Survival rate (%) instead of Fare.**\n",
        "\n",
        "---\n",
        "\n",
        "#### **🎯Summary**\n",
        "- The **`values`** parameter is always a **numerical column** (e.g., fare, survived, age).\n",
        "- The **`index`** represents **row categories** (e.g., class, embarked location).\n",
        "- The **`columns`** represent **column categories** (e.g., sex, day of the week).\n",
        "- The **`aggfunc`** tells **how to summarize** the numerical data (sum, mean, count).\n",
        "\n",
        "---\n",
        "\n",
        "## **📝 Syntax**\n",
        "```python\n",
        "df.pivot_table(values, index, columns, aggfunc)\n",
        "```\n",
        "| Parameter | Description |\n",
        "|-----------|------------|\n",
        "| `values`  | The column(s) to aggregate (numeric data) |\n",
        "| `index`   | The column(s) to group by (rows) |\n",
        "| `columns` | The column(s) to pivot (become new headers) |\n",
        "| `aggfunc` | The function to apply (default=`mean()`, but can be `sum()`, `count()`, etc.) |\n",
        "\n",
        "---\n",
        "\n",
        "## **🔹 Example: Creating a Pivot Table**\n",
        "### **🔹 Sample Data**\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample sales data\n",
        "data = {\n",
        "    \"Region\": [\"East\", \"West\", \"East\", \"West\", \"East\", \"West\"],\n",
        "    \"Product\": [\"A\", \"A\", \"B\", \"B\", \"C\", \"C\"],\n",
        "    \"Sales\": [200, 150, 300, 250, 400, 350]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "```\n",
        "📌 **DataFrame Before Pivoting:**\n",
        "```\n",
        "  Region Product  Sales\n",
        "0   East       A    200\n",
        "1   West       A    150\n",
        "2   East       B    300\n",
        "3   West       B    250\n",
        "4   East       C    400\n",
        "5   West       C    350\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **🔹 Basic Pivot Table**\n",
        "```python\n",
        "pivot_df = df.pivot_table(values=\"Sales\", index=\"Product\", columns=\"Region\", aggfunc=\"sum\")\n",
        "print(pivot_df)\n",
        "```\n",
        "📌 **Pivot Table Output:**\n",
        "```\n",
        "Region    East  West\n",
        "Product             \n",
        "A         200   150\n",
        "B         300   250\n",
        "C         400   350\n",
        "```\n",
        "- **Rows (`index`)** → `Product` (A, B, C).\n",
        "- **Columns (`columns`)** → `Region` (East, West).\n",
        "- **Values (`Sales`)** → Aggregated using `sum()`.\n",
        "\n",
        "---\n",
        "\n",
        "## **🔹 Multiple Aggregations**\n",
        "You can compute **multiple aggregations**:\n",
        "```python\n",
        "pivot_df = df.pivot_table(values=\"Sales\", index=\"Product\", columns=\"Region\", aggfunc=[\"sum\", \"mean\"])\n",
        "print(pivot_df)\n",
        "```\n",
        "📌 **Output (with sum & mean):**\n",
        "```\n",
        "         sum        mean      \n",
        "Region  East  West  East  West\n",
        "Product                        \n",
        "A       200   150   200   150\n",
        "B       300   250   300   250\n",
        "C       400   350   400   350\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **🔹 Counting Entries**\n",
        "You can use `count` instead of `sum`:\n",
        "```python\n",
        "pivot_df = df.pivot_table(values=\"Sales\", index=\"Region\", columns=\"Product\", aggfunc=\"count\")\n",
        "print(pivot_df)\n",
        "```\n",
        "📌 **Output (count of sales per product per region):**\n",
        "```\n",
        "Product  A  B  C\n",
        "Region         \n",
        "East     1  1  1\n",
        "West     1  1  1\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **🔹 Filling Missing Values**\n",
        "If some combinations don’t exist, you can **fill missing values**:\n",
        "```python\n",
        "pivot_df = df.pivot_table(values=\"Sales\", index=\"Product\", columns=\"Region\", aggfunc=\"sum\", fill_value=0)\n",
        "print(pivot_df)\n",
        "```\n",
        "📌 **This prevents `NaN` values**.\n",
        "\n",
        "---\n",
        "\n",
        "### **🚀 When to Use Pivot Tables?**\n",
        "✅ Summarizing large datasets.  \n",
        "✅ Aggregating numerical values (`sum`, `mean`, `count`).  \n",
        "✅ Reshaping data for easy analysis."
      ],
      "metadata": {
        "id": "TFBzIZRwetQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pivot table\n",
        "pivot_table = df.pivot_table(\n",
        "    values=\"Fare\",      # 🚀 The metric we want to analyze (numeric column)\n",
        "    index=\"Pclass\",     # 📌 Groups rows by Passenger Class\n",
        "    columns=\"Sex\",      # 📌 Groups columns by Sex\n",
        "    aggfunc=\"mean\",     # 📊 Summarizes using Average (Mean)\n",
        "    fill_value=0,       # 🔄 Fills missing values with 0\n",
        "    margins=True        # 📢 Adds total row/column\n",
        ")\n",
        "\n",
        "#pivot_table"
      ],
      "metadata": {
        "id": "kz38nqRnePwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **🔥 Challenge 5: Transforming Data Efficiently**\n",
        "🔹 **Task**:  \n",
        "Use `.transform()` to:\n",
        "- Normalize the `\"Fare\"` column **by Passenger Class** (subtract mean & divide by std within each class).\n",
        "\n",
        "🎯 **Goal:** Learn **`.transform()` to apply group-based calculations efficiently**."
      ],
      "metadata": {
        "id": "ZdC1uyK1GLJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔄 Understanding `transform()` vs. `apply()` in Pandas**\n",
        "Both **`transform()`** and **`apply()`** allow you to modify and manipulate data in **Pandas DataFrames and Series**, but they serve **different purposes**.\n",
        "\n",
        "---\n",
        "\n",
        "## **🚀 `apply()` - Apply a Function to Rows or Columns**\n",
        "### **When to Use?**\n",
        "✅ When you need to **apply a custom function** to a **whole row or column**.  \n",
        "✅ Can be used on **both Series & DataFrames**.  \n",
        "✅ Can return **a different shape** than the original (aggregation, reductions, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "### **📝 Example: Using `apply()` to Modify a Column**\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "    \"age\": [25, 30, 35]\n",
        "})\n",
        "\n",
        "# Apply a function to modify age\n",
        "df[\"age_category\"] = df[\"age\"].apply(lambda x: \"Young\" if x < 30 else \"Old\")\n",
        "print(df)\n",
        "```\n",
        "📌 **Output:**\n",
        "```\n",
        "     name  age age_category\n",
        "0   Alice   25       Young\n",
        "1     Bob   30        Old\n",
        "2  Charlie   35        Old\n",
        "```\n",
        "### **📝 Example: Using `apply()` to Modify an Entire Row**\n",
        "```python\n",
        "# Apply function to rows (axis=1)\n",
        "df[\"name_length\"] = df.apply(lambda row: len(row[\"name\"]), axis=1)\n",
        "print(df)\n",
        "```\n",
        "📌 **Output:**\n",
        "```\n",
        "     name  age age_category  name_length\n",
        "0   Alice   25       Young            5\n",
        "1     Bob   30        Old            3\n",
        "2  Charlie   35        Old            7\n",
        "```\n",
        "🔹 **Key Points:**\n",
        "- `apply()` can **modify** entire rows/columns.\n",
        "- **Flexible** → Can return a different shape.\n",
        "- Works on **both Series & DataFrames**.\n",
        "\n",
        "---\n",
        "\n",
        "## **🚀 `transform()` - Element-wise Transformations**\n",
        "### **When to Use?**\n",
        "✅ When you need to **modify each element in a column individually**.  \n",
        "✅ The result **must have the same shape** as the original data.  \n",
        "✅ Works **only on Series or DataFrame columns**.\n",
        "\n",
        "---\n",
        "\n",
        "### **📝 Example: Using `transform()` for Normalization**\n",
        "```python\n",
        "df[\"normalized_age\"] = df[\"age\"].transform(lambda x: (x - x.mean()) / x.std())\n",
        "print(df)\n",
        "```\n",
        "📌 **Output:**\n",
        "```\n",
        "     name  age age_category  name_length  normalized_age\n",
        "0   Alice   25       Young            5       -1.224745\n",
        "1     Bob   30        Old            3        0.000000\n",
        "2  Charlie   35        Old            7        1.224745\n",
        "```\n",
        "🔹 **Key Points:**\n",
        "- **Applies element-wise functions.**\n",
        "- **Maintains the same shape** as the original column.\n",
        "- Often used for **group-wise transformations** (see below).\n",
        "\n",
        "---\n",
        "\n",
        "## **🚀 `transform()` vs. `apply()` for Grouped Operations**\n",
        "### **📝 Example: Compute Mean Age per Category**\n",
        "#### **✅ Using `apply()` (returns a Series)**\n",
        "```python\n",
        "df[\"group_mean_apply\"] = df.groupby(\"age_category\")[\"age\"].apply(lambda x: x.mean())\n",
        "print(df)\n",
        "```\n",
        "📌 Output:\n",
        "```\n",
        "     name  age age_category  group_mean_apply\n",
        "0   Alice   25       Young               25.0\n",
        "1     Bob   30        Old               32.5\n",
        "2  Charlie   35        Old               32.5\n",
        "```\n",
        "🔹 `apply()` **creates a new Series** that is merged back.\n",
        "\n",
        "#### **✅ Using `transform()` (keeps same shape)**\n",
        "```python\n",
        "df[\"group_mean_transform\"] = df.groupby(\"age_category\")[\"age\"].transform(\"mean\")\n",
        "print(df)\n",
        "```\n",
        "📌 Output:\n",
        "```\n",
        "     name  age age_category  group_mean_transform\n",
        "0   Alice   25       Young               25.0\n",
        "1     Bob   30        Old               32.5\n",
        "2  Charlie   35        Old               32.5\n",
        "```\n",
        "🔹 `transform()` **keeps the same shape** as the original column.\n",
        "\n",
        "---\n",
        "\n",
        "## **🎯 When to Use `apply()` vs `transform()`**\n",
        "| **Scenario** | **Use `apply()`** | **Use `transform()`** |\n",
        "|-------------|----------------|----------------|\n",
        "| Apply function **row-wise (axis=1)** | ✅ | ❌ |\n",
        "| Apply function **column-wise (axis=0)** | ✅ | ✅ |\n",
        "| Aggregation (mean, sum, count, etc.) | ✅ | ❌ |\n",
        "| Element-wise transformations (scaling, normalizing) | ❌ | ✅ |\n",
        "| Returning a **different shape** | ✅ | ❌ |\n",
        "| Returning **same shape** as input | ❌ | ✅ |\n",
        "\n",
        "---\n",
        "\n",
        "### **💡 Quick Rule of Thumb**\n",
        "- **Use `apply()`** when **you don’t care about output shape** (modifying rows, summarizing data).\n",
        "- **Use `transform()`** when **you need the same shape as the input** (scaling, normalizing, filling missing values)."
      ],
      "metadata": {
        "id": "TZGI-3LDwyy_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **🔥 Super Challenge: Write an Efficient Data Pipeline**\n",
        "🔹 **Task**:  \n",
        "1. Fill missing **Ages** with the median **by Pclass**.  \n",
        "2. Convert **Sex** to **0/1** (`male=1, female=0`).  \n",
        "3. Normalize **Fare** within each class.  \n",
        "4. Output the transformed **clean dataset**.\n",
        "\n",
        "🎯 **Goal:** Chain multiple transformations efficiently."
      ],
      "metadata": {
        "id": "Zn61z1Wnxcv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Fare_Normalized\"] = df.groupby(\"Pclass\")[\"Fare\"].transform(lambda x: (x - x.mean()) / x.std())\n",
        "df[[\"Pclass\", \"Fare\", \"Fare_Normalized\"]].head()\n",
        "df[\"Age\"] = df.groupby(\"Pclass\")[\"Age\"].transform(lambda x: x.fillna(x.median))\n",
        "df[\"Sex\"] = df[\"Sex\"].transform(lambda x: \"1\" if x == \"male\" else \"0\")\n",
        "df[\"Sex\"].head()\n",
        "df[\"Fare\"] = df.groupby(\"Pclass\")[\"Fare\"].transform(lambda x: (x - x.mean()) / x.std())\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7KBbzN_1GK6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔥 **Pandas Date & Datetime Mastery in Record Time**\n",
        "Instead of a traditional tutorial, we’ll use a **high-impact, hands-on approach** focusing on the **20% of functions that cover 80% of real-world use cases**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 1: Creating & Converting Datetime Objects**\n",
        "### **✅ 1. Load a dataset with dates**\n",
        "Pandas doesn’t always recognize dates automatically. You need to **convert them explicitly**.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame with date strings\n",
        "data = {\"date\": [\"2023-03-15\", \"2024-01-10\", \"2022-06-21\"]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert string to datetime\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "\n",
        "print(df.dtypes)  # Check data type\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Try running `df[\"date\"] = pd.to_datetime(df[\"date\"])` **without specifying a format**.\n",
        "- Now, try **forcing a format**:  \n",
        "  ```python\n",
        "  df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%d\")\n",
        "  ```\n",
        "\n",
        "✅ **Why does it matter?**  \n",
        "- If your dataset has dates in **weird formats**, Pandas might **misinterpret them** (e.g., `01-02-2024` → Is this Jan 2 or Feb 1?).\n",
        "- `format=\"%Y-%m-%d\"` ensures **consistent interpretation**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 2: Extracting Useful Date Components**\n",
        "Once you have a datetime column, **you can extract insights**:\n",
        "\n",
        "```python\n",
        "df[\"year\"] = df[\"date\"].dt.year\n",
        "df[\"month\"] = df[\"date\"].dt.month\n",
        "df[\"day\"] = df[\"date\"].dt.day\n",
        "df[\"weekday\"] = df[\"date\"].dt.day_name()  # Get weekday name\n",
        "\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Extract **only the month names** (`df[\"date\"].dt.month_name()`).\n",
        "- Extract **week number** (`df[\"date\"].dt.isocalendar().week`).\n",
        "\n",
        "✅ **Why does it matter?**  \n",
        "- Useful for **time-based grouping** (e.g., analyzing sales by month or week).\n",
        "- Helps in **trend detection** (e.g., sales peak on Mondays).\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 3: Handling Time Components (Hour, Minute, Second)**\n",
        "```python\n",
        "# Adding a datetime with time component\n",
        "df[\"date\"] = pd.to_datetime([\"2023-03-15 14:30:00\", \"2024-01-10 08:15:00\", \"2022-06-21 22:45:00\"])\n",
        "\n",
        "# Extract time components\n",
        "df[\"hour\"] = df[\"date\"].dt.hour\n",
        "df[\"minute\"] = df[\"date\"].dt.minute\n",
        "df[\"second\"] = df[\"date\"].dt.second\n",
        "\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Extract **only the time**: `df[\"time\"] = df[\"date\"].dt.time`\n",
        "- Extract **AM/PM indicator**: `df[\"AM_PM\"] = df[\"date\"].dt.strftime('%p')`\n",
        "\n",
        "✅ **Why does it matter?**  \n",
        "- Essential for **hourly trend analysis** (e.g., most active hours in a dataset).\n",
        "- Helps with **time-based filtering** (e.g., filter data for morning or evening).\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 4: Date Arithmetic (Adding & Subtracting Dates)**\n",
        "🔹 **Adding or subtracting days, months, or years:**\n",
        "```python\n",
        "df[\"next_week\"] = df[\"date\"] + pd.DateOffset(weeks=1)  # Add 1 week\n",
        "df[\"prev_month\"] = df[\"date\"] - pd.DateOffset(months=1)  # Subtract 1 month\n",
        "df[\"next_year\"] = df[\"date\"] + pd.DateOffset(years=1)  # Add 1 year\n",
        "\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Subtract **1 day**: `df[\"yesterday\"] = df[\"date\"] - pd.Timedelta(days=1)`\n",
        "- Add **3 hours**: `df[\"3_hours_later\"] = df[\"date\"] + pd.Timedelta(hours=3)`\n",
        "\n",
        "✅ **Why does it matter?**  \n",
        "- Useful for **rolling window analysis** (e.g., calculate values for the previous week).\n",
        "- Helps in **scheduling and forecasting**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 5: Filtering & Comparing Dates**\n",
        "### **🔎 Find data within a date range**\n",
        "```python\n",
        "start_date = \"2023-01-01\"\n",
        "end_date = \"2024-01-01\"\n",
        "\n",
        "df_filtered = df[(df[\"date\"] >= start_date) & (df[\"date\"] <= end_date)]\n",
        "print(df_filtered)\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Filter only for **weekends**:  \n",
        "  ```python\n",
        "  df_weekends = df[df[\"date\"].dt.weekday >= 5]  # 5 = Saturday, 6 = Sunday\n",
        "  ```\n",
        "- Filter for dates **before 2023**:  \n",
        "  ```python\n",
        "  df_before_2023 = df[df[\"date\"] < \"2023-01-01\"]\n",
        "  ```\n",
        "\n",
        "✅ **Why does it matter?**  \n",
        "- Crucial for **time-based data filtering** (e.g., select only last month's data).\n",
        "- Helps in **trend analysis over specific time periods**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 6: Resampling (Grouping Data by Time)**\n",
        "🔹 **Convert raw timestamps into summarized time periods**:\n",
        "\n",
        "```python\n",
        "df.set_index(\"date\", inplace=True)  # Set datetime as index\n",
        "\n",
        "# Resample by month (get average values for each month)\n",
        "monthly_data = df.resample(\"M\").mean()\n",
        "\n",
        "# Resample by week\n",
        "weekly_data = df.resample(\"W\").mean()\n",
        "\n",
        "print(monthly_data.head())\n",
        "print(weekly_data.head())\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Resample **by quarter (`Q`)**.\n",
        "- Resample **by day (`D`)**.\n",
        "\n",
        "✅ **Why does it matter?**  \n",
        "- Used for **time-series analysis** (e.g., sales trends by month).\n",
        "- Helps to **smooth noisy data** and find patterns.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 7: Handling Time Zones**\n",
        "🔹 **Convert between time zones**:\n",
        "```python\n",
        "df[\"date\"] = df[\"date\"].dt.tz_localize(\"UTC\")  # Set UTC timezone\n",
        "df[\"date_pacific\"] = df[\"date\"].dt.tz_convert(\"America/Los_Angeles\")  # Convert to LA time\n",
        "\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Convert dates **to \"Asia/Tokyo\" time zone**.\n",
        "- Convert a timestamp to **\"Europe/London\"**.\n",
        "\n",
        "✅ **Why does it matter?**  \n",
        "- Essential for **global datasets** (e.g., aligning timestamps from different regions).\n",
        "- Important in **stock market & server log analysis**.\n",
        "\n",
        "---\n",
        "\n",
        "## **🔥 Final Boss Challenge**\n",
        "🎯 **Goal: Clean & Analyze a Date Dataset**\n",
        "1. Load the Titanic dataset.\n",
        "2. Convert `\"Date of Journey\"` column into a proper **datetime format**.\n",
        "3. Extract **year, month, day, and weekday**.\n",
        "4. Filter **only passengers who traveled on a weekend**.\n",
        "5. Calculate **how many passengers traveled in each month**.\n",
        "6. Export results to `\"titanic_dates_cleaned.csv\"`.\n",
        "\n",
        "---\n",
        "\n",
        "## **🔥 Recap: The 80/20 Pandas Datetime Mastery Formula**\n",
        "| **Task** | **Essential Pandas Function** |\n",
        "|----------|-----------------------------|\n",
        "| Convert string to datetime | `pd.to_datetime()` |\n",
        "| Extract date parts | `.dt.year`, `.dt.month`, `.dt.day_name()` |\n",
        "| Add/subtract time | `pd.DateOffset()` & `pd.Timedelta()` |\n",
        "| Filter dates | `df[df[\"date\"] >= \"2023-01-01\"]` |\n",
        "| Resample data | `df.resample(\"M\").mean()` |\n",
        "| Convert time zones | `.dt.tz_localize()` & `.dt.tz_convert()` |\n",
        "\n",
        "⏳ **Total Time: ~2 hours**  \n",
        "By the end, you’ll **master date handling & time-series data in Pandas**.\n",
        "\n",
        "---\n",
        "\n",
        "### **💡 Ready to tackle the final challenge, or do you want a real dataset to practice on? 🚀**"
      ],
      "metadata": {
        "id": "1YY0nin9bbxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔥 **Master SQL Commands in Pandas in Record Time**\n",
        "Instead of going through **traditional SQL tutorials**, let’s focus on the **80/20** rule: mastering the **20% of SQL operations** that cover **80% of real-world data manipulation** using **Pandas**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 1: Loading Data into Pandas**\n",
        "Before running SQL-like operations, let’s load a dataset into Pandas.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Load Titanic dataset\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(df.head())  # Display first 5 rows\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**\n",
        "- Run `df.info()` to check **column types**.\n",
        "- Run `df.describe()` to get **summary statistics**.\n",
        "\n",
        "✅ **Why?** Before running SQL-like queries, you should **always inspect your dataset**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 2: SQL Equivalent of `SELECT` (Column Selection)**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT Name, Age, Sex FROM df;\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "df[[\"Name\", \"Age\", \"Sex\"]]\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Select only `\"Survived\"`, `\"Pclass\"`, and `\"Fare\"` columns.\n",
        "\n",
        "✅ **Why?** Selecting columns is a fundamental operation in **data exploration & preprocessing**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 3: SQL Equivalent of `WHERE` (Filtering Rows)**\n",
        "### **1️⃣ Filter based on a single condition**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT * FROM df WHERE Age > 30;\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "df[df[\"Age\"] > 30]\n",
        "```\n",
        "\n",
        "### **2️⃣ Filter based on multiple conditions**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT * FROM df WHERE Age > 30 AND Sex = 'female';\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "df[(df[\"Age\"] > 30) & (df[\"Sex\"] == \"female\")]\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Filter passengers who **paid a fare greater than 50** and **are male**.\n",
        "\n",
        "✅ **Why?** Filtering is crucial for **data cleaning & analysis**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 4: SQL Equivalent of `ORDER BY` (Sorting)**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT * FROM df ORDER BY Age DESC;\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "df.sort_values(by=\"Age\", ascending=False)\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Sort passengers **by Fare (highest to lowest).**\n",
        "\n",
        "✅ **Why?** Sorting helps in **ranking and analyzing distributions**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 5: SQL Equivalent of `GROUP BY` (Aggregation)**\n",
        "### **1️⃣ Group by a single column**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT Pclass, AVG(Fare) FROM df GROUP BY Pclass;\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "df.groupby(\"Pclass\")[\"Fare\"].mean()\n",
        "```\n",
        "\n",
        "### **2️⃣ Group by multiple columns**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT Pclass, Sex, AVG(Age) FROM df GROUP BY Pclass, Sex;\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "df.groupby([\"Pclass\", \"Sex\"])[\"Age\"].mean()\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Find the **average Fare and Age per class (`Pclass`)**.\n",
        "\n",
        "✅ **Why?** Aggregation is **key for summarizing data**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 6: SQL Equivalent of `HAVING` (Filtering After Aggregation)**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT Pclass, AVG(Fare) FROM df GROUP BY Pclass HAVING AVG(Fare) > 20;\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "df.groupby(\"Pclass\")[\"Fare\"].mean().reset_index().query(\"Fare > 20\")\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Filter only **groups where the average age is above 30**.\n",
        "\n",
        "✅ **Why?** `HAVING` is useful when filtering **aggregated results**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 7: SQL Equivalent of `JOIN` (Merging Tables)**\n",
        "### **Creating Two DataFrames**\n",
        "```python\n",
        "# Sample passengers table\n",
        "passengers = df[[\"PassengerId\", \"Name\", \"Pclass\"]]\n",
        "\n",
        "# Sample fares table\n",
        "fares = df[[\"PassengerId\", \"Fare\"]]\n",
        "\n",
        "print(passengers.head(), fares.head())\n",
        "```\n",
        "\n",
        "### **1️⃣ INNER JOIN (Default in Pandas)**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT * FROM passengers INNER JOIN fares ON passengers.PassengerId = fares.PassengerId;\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "merged_df = passengers.merge(fares, on=\"PassengerId\", how=\"inner\")\n",
        "```\n",
        "\n",
        "### **2️⃣ LEFT JOIN**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT * FROM passengers LEFT JOIN fares ON passengers.PassengerId = fares.PassengerId;\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "merged_df = passengers.merge(fares, on=\"PassengerId\", how=\"left\")\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Merge the `passengers` and `fares` DataFrames using an **inner join**.\n",
        "\n",
        "✅ **Why?** `JOINs` allow combining **multiple datasets** into a single DataFrame.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 8: SQL Equivalent of `UNION` (Concatenation)**\n",
        "### **Stacking Two DataFrames**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT * FROM df1 UNION SELECT * FROM df2;\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "df_union = pd.concat([df1, df2])\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Create two DataFrames with different rows and **combine them using `concat()`**.\n",
        "\n",
        "✅ **Why?** Useful for **appending new data** (e.g., multiple years of records).\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 9: SQL Equivalent of `LIMIT` (Selecting Top Rows)**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT * FROM df LIMIT 5;\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "df.head(5)\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Select **the top 10 passengers who paid the highest Fare**.\n",
        "\n",
        "✅ **Why?** `LIMIT` is useful for **previewing data**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📌 Step 10: SQL Equivalent of `CASE` (Conditional Column)**\n",
        "**SQL Query:**\n",
        "```sql\n",
        "SELECT Name, Age,\n",
        "    CASE\n",
        "        WHEN Age < 18 THEN 'Child'\n",
        "        WHEN Age >= 18 AND Age < 60 THEN 'Adult'\n",
        "        ELSE 'Senior'\n",
        "    END AS AgeGroup\n",
        "FROM df;\n",
        "```\n",
        "**Pandas Equivalent:**\n",
        "```python\n",
        "df[\"AgeGroup\"] = df[\"Age\"].apply(lambda x: \"Child\" if x < 18 else (\"Senior\" if x >= 60 else \"Adult\"))\n",
        "```\n",
        "\n",
        "🎯 **Your Task:**  \n",
        "- Create a column **\"FareCategory\"** where:\n",
        "  - `< 10`: `\"Low\"`\n",
        "  - `10 - 50`: `\"Medium\"`\n",
        "  - `> 50`: `\"High\"`\n",
        "\n",
        "✅ **Why?** Conditional transformations are useful for **feature engineering**.\n",
        "\n",
        "---\n",
        "\n",
        "## **🔥 Final Boss Challenge: Titanic SQL Simulation**\n",
        "🎯 **Goal: Replicate this SQL query in Pandas**\n",
        "```sql\n",
        "SELECT Pclass, Sex, COUNT(*) AS Passengers, AVG(Age) AS AvgAge, AVG(Fare) AS AvgFare\n",
        "FROM df\n",
        "WHERE Age IS NOT NULL\n",
        "GROUP BY Pclass, Sex\n",
        "HAVING COUNT(*) > 50\n",
        "ORDER BY AvgFare DESC;\n",
        "```\n",
        "---\n",
        "\n",
        "## **🔥 Recap: SQL → Pandas Mapping**\n",
        "| **SQL Command**  | **Pandas Equivalent** |\n",
        "|-----------------|---------------------|\n",
        "| `SELECT` | `df[[\"col1\", \"col2\"]]` |\n",
        "| `WHERE` | `df[df[\"col\"] > value]` |\n",
        "| `ORDER BY` | `df.sort_values(by=\"col\")` |\n",
        "| `GROUP BY` | `df.groupby(\"col\").agg()` |\n",
        "| `HAVING` | `.query()` |\n",
        "| `JOIN` | `df.merge()` |\n",
        "| `UNION` | `pd.concat()` |\n",
        "| `LIMIT` | `df.head(n)` |\n",
        "| `CASE` | `.apply(lambda x: ...)` |\n",
        "\n",
        "🚀 **Now you can handle SQL-like queries in Pandas like a pro!** Let me know if you want **practice exercises!** 🔥"
      ],
      "metadata": {
        "id": "gAp20b0n5Atn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sN6tqz5tUtV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_oR7As8uSm9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📌 Pandas Ultimate Cheat Sheet: Functions, Examples, & Advanced Tips 🚀**  \n",
        "This **cheat sheet** covers **all Pandas functions** we’ve studied, their **use cases**, and **advanced techniques** to handle real-world datasets.\n",
        "\n",
        "---\n",
        "\n",
        "# **🔹 1. Importing & Loading Data**\n",
        "| **Function** | **Use Case** | **Example** |\n",
        "|-------------|-------------|-------------|\n",
        "| `pd.read_csv()` | Load CSV file | `df = pd.read_csv(\"data.csv\")` |\n",
        "| `pd.read_excel()` | Load Excel file | `df = pd.read_excel(\"data.xlsx\")` |\n",
        "| `pd.read_json()` | Load JSON file | `df = pd.read_json(\"data.json\")` |\n",
        "| `df.to_csv()` | Save DataFrame to CSV | `df.to_csv(\"output.csv\", index=False)` |\n",
        "| `df.to_excel()` | Save DataFrame to Excel | `df.to_excel(\"output.xlsx\", index=False)` |\n",
        "\n",
        "💡 **Advanced Hint**: Use `chunksize=1000` in `read_csv()` for **large files**:  \n",
        "```python\n",
        "for chunk in pd.read_csv(\"large_file.csv\", chunksize=1000):\n",
        "    process(chunk)  # Process each chunk separately\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **🔹 2. Inspecting & Exploring Data**\n",
        "| **Function** | **Use Case** | **Example** |\n",
        "|-------------|-------------|-------------|\n",
        "| `df.head(n)` | View first `n` rows | `df.head(10)` |\n",
        "| `df.tail(n)` | View last `n` rows | `df.tail(5)` |\n",
        "| `df.info()` | Check column types & nulls | `df.info()` |\n",
        "| `df.describe()` | Summary stats | `df.describe()` |\n",
        "| `df.shape` | Get (rows, columns) | `df.shape` |\n",
        "| `df.columns` | Get column names | `df.columns` |\n",
        "\n",
        "💡 **Advanced Hint**: Check memory usage with:\n",
        "```python\n",
        "df.memory_usage(deep=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **🔹 3. Selecting & Filtering Data**\n",
        "| **Function** | **Use Case** | **Example** |\n",
        "|-------------|-------------|-------------|\n",
        "| `df[\"col\"]` | Select single column | `df[\"Age\"]` |\n",
        "| `df[[\"col1\", \"col2\"]]` | Select multiple columns | `df[[\"Age\", \"Fare\"]]` |\n",
        "| `df.iloc[]` | Select rows/cols by index | `df.iloc[0:5, 1:3]` |\n",
        "| `df.loc[]` | Select by labels | `df.loc[df[\"Age\"] > 30, [\"Name\", \"Age\"]]` |\n",
        "| `df[df[\"Age\"] > 30]` | Filter rows | `df[df[\"Sex\"] == \"male\"]` |\n",
        "\n",
        "💡 **Advanced Hint**: Use `query()` for cleaner filtering:\n",
        "```python\n",
        "df.query(\"Age > 30 & Sex == 'male'\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **🔹 4. Sorting & Ordering**\n",
        "| **Function** | **Use Case** | **Example** |\n",
        "|-------------|-------------|-------------|\n",
        "| `df.sort_values()` | Sort rows by column | `df.sort_values(by=\"Age\", ascending=False)` |\n",
        "| `df.sort_index()` | Sort by row index | `df.sort_index()` |\n",
        "\n",
        "💡 **Advanced Hint**: Sort by multiple columns:\n",
        "```python\n",
        "df.sort_values(by=[\"Pclass\", \"Fare\"], ascending=[True, False])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **🔹 5. Handling Missing Data**\n",
        "| **Function** | **Use Case** | **Example** |\n",
        "|-------------|-------------|-------------|\n",
        "| `df.isnull().sum()` | Count null values | `df.isnull().sum()` |\n",
        "| `df.dropna()` | Drop missing rows | `df.dropna()` |\n",
        "| `df.fillna(value)` | Fill missing values | `df.fillna(df[\"Age\"].median())` |\n",
        "\n",
        "💡 **Advanced Hint**: Fill missing values by **group**:\n",
        "```python\n",
        "df[\"Age\"] = df.groupby(\"Pclass\")[\"Age\"].transform(lambda x: x.fillna(x.median()))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **🔹 6. Grouping & Aggregation**\n",
        "| **Function** | **Use Case** | **Example** |\n",
        "|-------------|-------------|-------------|\n",
        "| `df.groupby(\"col\")` | Group by column | `df.groupby(\"Pclass\")[\"Fare\"].mean()` |\n",
        "| `df.agg()` | Apply multiple agg functions | `df.groupby(\"Sex\").agg({\"Age\": \"mean\", \"Fare\": \"sum\"})` |\n",
        "\n",
        "💡 **Advanced Hint**: Use `.transform()` to retain original DataFrame shape:\n",
        "```python\n",
        "df[\"AvgFareByClass\"] = df.groupby(\"Pclass\")[\"Fare\"].transform(\"mean\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **🔹 7. Creating & Modifying Columns**\n",
        "| **Function** | **Use Case** | **Example** |\n",
        "|-------------|-------------|-------------|\n",
        "| `df[\"new_col\"] = value` | Add new column | `df[\"AgeSquared\"] = df[\"Age\"] ** 2` |\n",
        "| `df[\"col\"].apply()` | Apply function to column | `df[\"FareCategory\"] = df[\"Fare\"].apply(lambda x: \"Low\" if x < 10 else \"High\")` |\n",
        "\n",
        "💡 **Advanced Hint**: Use `.map()` for fast categorical mapping:\n",
        "```python\n",
        "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **🔹 8. Merging & Joining Data**\n",
        "| **Function** | **Use Case** | **Example** |\n",
        "|-------------|-------------|-------------|\n",
        "| `df1.merge(df2, on=\"col\")` | SQL-style join | `df1.merge(df2, on=\"PassengerId\", how=\"inner\")` |\n",
        "| `pd.concat([df1, df2])` | Append rows | `df_concat = pd.concat([df1, df2])` |\n",
        "\n",
        "💡 **Advanced Hint**: Merge on multiple keys:\n",
        "```python\n",
        "df1.merge(df2, on=[\"PassengerId\", \"Pclass\"], how=\"left\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **🔹 9. Working with Dates**\n",
        "| **Function** | **Use Case** | **Example** |\n",
        "|-------------|-------------|-------------|\n",
        "| `pd.to_datetime()` | Convert to datetime | `df[\"date\"] = pd.to_datetime(df[\"date\"])` |\n",
        "| `df[\"date\"].dt.year` | Extract year | `df[\"year\"] = df[\"date\"].dt.year` |\n",
        "| `df.resample(\"M\")` | Resample by month | `df.set_index(\"date\").resample(\"M\").mean()` |\n",
        "\n",
        "💡 **Advanced Hint**: Extract day of the week:\n",
        "```python\n",
        "df[\"Weekday\"] = df[\"date\"].dt.day_name()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# **🔹 10. Exporting Data**\n",
        "| **Function** | **Use Case** | **Example** |\n",
        "|-------------|-------------|-------------|\n",
        "| `df.to_csv()` | Save as CSV | `df.to_csv(\"output.csv\", index=False)` |\n",
        "| `df.to_excel()` | Save as Excel | `df.to_excel(\"output.xlsx\", index=False)` |\n",
        "\n",
        "---\n",
        "\n",
        "# **🔥 Advanced Challenges**\n",
        "### **🔹 1. Filter Passengers:**\n",
        "- Who are **older than 30**  \n",
        "- **Paid more than 50**  \n",
        "- **Survived**\n",
        "\n",
        "✅ **Hint**:\n",
        "```python\n",
        "df_filtered = df[(df[\"Age\"] > 30) & (df[\"Fare\"] > 50) & (df[\"Survived\"] == 1)]\n",
        "```\n",
        "\n",
        "### **🔹 2. Find the Average Fare by Class & Gender**\n",
        "✅ **Hint**:\n",
        "```python\n",
        "df.groupby([\"Pclass\", \"Sex\"])[\"Fare\"].mean()\n",
        "```\n",
        "\n",
        "### **🔹 3. Create a New Column: \"AgeGroup\"**\n",
        "✅ **Hint**:\n",
        "```python\n",
        "df[\"AgeGroup\"] = df[\"Age\"].apply(lambda x: \"Child\" if x < 18 else (\"Senior\" if x > 60 else \"Adult\"))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **🔥 Final Challenge**\n",
        "Can you:\n",
        "\n",
        "1️⃣ Load Titanic dataset?  \n",
        "2️⃣ Fill missing ages **by class median**?  \n",
        "3️⃣ Create an **\"AgeGroup\"** column?  \n",
        "4️⃣ Find **average Fare per class**?  \n",
        "5️⃣ Save cleaned data to CSV?  \n",
        "\n",
        "🚀 **If you can, you're a Pandas expert!** 🔥"
      ],
      "metadata": {
        "id": "NUYvh8guZFf7"
      }
    }
  ]
}