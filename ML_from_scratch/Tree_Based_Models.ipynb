{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ“Œ 2. Tree-Based Models**\n",
        "âœ… **Used For:** Capturing non-linear relationships, feature importance.\n",
        "\n",
        "| Model | Use Case | Key Concept |\n",
        "|-------|----------|------------|\n",
        "| **Decision Trees** | Regression & Classification | Recursive splitting on feature values |\n",
        "| **Random Forest** | Regression & Classification | Bagging ensemble of decision trees |\n",
        "| **Gradient Boosting (GBDT)** | Regression & Classification | Iteratively improves weak learners |\n",
        "| **XGBoost / LightGBM / CatBoost** | Regression & Classification | Optimized gradient boosting libraries |"
      ],
      "metadata": {
        "id": "bDhkAhH4Ls_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ðŸ“Œ 2. Implementation from Scratch**\n",
        "\n",
        "**Preprocesing Titanic Dataset**\n"
      ],
      "metadata": {
        "id": "OYFHoezxCp6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df[\"Age\"] = df.groupby(\"Pclass\")[\"Age\"].transform(lambda x: x.fillna(x.median()))\n",
        "df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])\n",
        "df.drop(columns=[\"Cabin\", \"Ticket\", \"Name\"], inplace=True)\n",
        "\n",
        "# New variables\n",
        "df[\"family_size\"] = df[\"SibSp\"] + df[\"Parch\"]\n",
        "df.drop(columns=[\"SibSp\", \"Parch\"], inplace=True)\n",
        "\n",
        "# Transformations\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# Categorical features\n",
        "cat_features = [\"Sex\", \"Embarked\"]\n",
        "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
        "encoded_cat = encoder.fit_transform(df[cat_features]) # Encoded array\n",
        "encoded_df = pd.DataFrame(encoded_cat, columns=encoder.get_feature_names_out(cat_features))\n",
        "\n",
        "df = df.drop(columns=cat_features).reset_index(drop=True)\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "# Numerical variables\n",
        "scaler = StandardScaler()\n",
        "\n",
        "df[\"Age\"] = scaler.fit_transform(df[[\"Age\"]])\n",
        "df[\"Fare\"] = scaler.fit_transform(df[[\"Fare\"]])\n",
        "df.head()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "y = df[\"Survived\"]\n",
        "X = df.drop(columns=[\"Survived\"])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3KDPEiThYJZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ðŸ“Œ 3. Implementation Using Libraries**"
      ],
      "metadata": {
        "id": "c4JJZc5IDnwO"
      }
    }
  ]
}